//! Comprehensive Load Test for AI Agent System
//!
//! This test simulates:
//! - Hundreds of IoT devices generating metrics
//! - Real-time data injection into event bus
//! - Agent execution with large datasets
//! - Command execution rates
//! - Performance metrics under load

use std::sync::Arc;
use std::time::{Duration, Instant};
use neomind_core::{EventBus, MetricValue, NeoMindEvent};
use neomind_storage::{
    AgentStore, AgentSchedule, AgentStats, AgentStatus, AiAgent, AgentMemory,
    WorkingMemory, ShortTermMemory, LongTermMemory, ScheduleType,
};
use neomind_agent::ai_agent::{AgentExecutor, AgentExecutorConfig};
use neomind_llm::backends::ollama::{OllamaRuntime, OllamaConfig};

// ============================================================================
// Test Metrics
// ============================================================================

#[derive(Debug, Default)]
struct TestMetrics {
    pub total_devices: usize,
    pub total_metrics: usize,
    pub total_executions: usize,
    pub successful_executions: usize,
    pub failed_executions: usize,
    pub avg_execution_time_ms: u64,
    pub min_execution_time_ms: u64,
    pub max_execution_time_ms: u64,
    pub data_collection_time_ms: u64,
    pub llm_call_time_ms: u64,
    pub total_data_points_processed: usize,
}

impl TestMetrics {
    fn print_summary(&self) {
        println!("\n{}", "=".repeat(70));
        println!("测试结果汇总");
        println!("{}", "=".repeat(70));
        println!("设备数量: {}", self.total_devices);
        println!("指标总数: {}", self.total_metrics);
        println!("执行次数: {}", self.total_executions);
        println!("成功执行: {} ({:.1}%)", self.successful_executions,
            (self.successful_executions as f64 / self.total_executions as f64) * 100.0);
        println!("失败执行: {}", self.failed_executions);
        println!("\n执行时间统计:");
        println!("  平均: {}ms", self.avg_execution_time_ms);
        println!("  最小: {}ms", self.min_execution_time_ms);
        println!("  最大: {}ms", self.max_execution_time_ms);
        println!("\n详细统计:");
        println!("  数据收集时间: {}ms", self.data_collection_time_ms);
        println!("  LLM调用时间: {}ms", self.llm_call_time_ms);
        println!("  处理的数据点: {}", self.total_data_points_processed);

        if self.avg_execution_time_ms > 0 {
            let throughput = (self.total_data_points_processed as f64 / self.avg_execution_time_ms as f64) * 1000.0;
            println!("  吞吐量: {:.1} 数据点/秒", throughput);
        }
        println!("{}", "=".repeat(70));
    }
}

// ============================================================================
// Simulated IoT Device
// ============================================================================

struct SimulatedDevice {
    id: String,
    name: String,
    location: String,
    metrics: Vec<String>,
    base_values: Vec<f64>,
    variance: f64,
}

impl SimulatedDevice {
    fn new(id: String, name: String, location: String) -> Self {
        Self {
            id,
            name,
            location,
            metrics: vec![
                "temperature".to_string(),
                "humidity".to_string(),
                "pressure".to_string(),
            ],
            base_values: vec![25.0, 50.0, 1013.25],
            variance: 2.0,
        }
    }

    fn with_metrics(mut self, metrics: Vec<String>) -> Self {
        self.metrics = metrics;
        self
    }

    fn with_base_values(mut self, values: Vec<f64>) -> Self {
        self.base_values = values;
        self
    }

    fn generate_metrics(&self) -> Vec<(String, f64)> {
        let mut result = Vec::new();
        for (i, metric) in self.metrics.iter().enumerate() {
            let base = self.base_values.get(i).unwrap_or(&0.0);
            let noise = (rand::random::<f64>() - 0.5) * 2.0 * self.variance;
            result.push((metric.clone(), base + noise));
        }
        result
    }

    fn generate_historical_metrics(&self, count: usize) -> Vec<(i64, Vec<(String, f64)>)> {
        let now = chrono::Utc::now().timestamp();
        let mut result = Vec::new();

        for i in 0..count {
            let timestamp = now - (count - i) as i64 * 60; // One per minute
            let metrics = self.generate_metrics();
            result.push((timestamp, metrics));
        }

        result
    }
}

// ============================================================================
// Test Context
// ============================================================================

struct LoadTestContext {
    pub store: Arc<AgentStore>,
    pub executor: AgentExecutor,
    pub event_bus: Arc<EventBus>,
    pub devices: Vec<SimulatedDevice>,
    pub llm_runtime: Option<Arc<dyn neomind_core::llm::backend::LlmRuntime + Send + Sync>>,
}

impl LoadTestContext {
    async fn new_with_llm(use_llm: bool) -> anyhow::Result<Self> {
        let store = AgentStore::memory()?;
        let event_bus = Arc::new(EventBus::new());

        let llm_runtime = if use_llm {
            let ollama_config = OllamaConfig {
                endpoint: "http://localhost:11434".to_string(),
                model: "qwen2.5:3b".to_string(),
                timeout_secs: 120,
            };
            Some(Arc::new(OllamaRuntime::new(ollama_config)?) as Arc<dyn neomind_core::llm::backend::LlmRuntime + Send + Sync>)
        } else {
            None
        };

        let executor_config = AgentExecutorConfig {
            store: store.clone(),
            time_series_storage: None,
            device_service: None,
            event_bus: Some(event_bus.clone()),
            message_manager: None,
            llm_runtime: llm_runtime.clone(),
            llm_backend_store: None,
            extension_registry: None,
        };

        let executor = AgentExecutor::new(executor_config).await?;

        Ok(Self {
            store,
            executor,
            event_bus,
            devices: Vec::new(),
            llm_runtime,
        })
    }

    async fn create_test_agent(
        &self,
        name: &str,
        user_prompt: &str,
    ) -> anyhow::Result<AiAgent> {
        let now = chrono::Utc::now().timestamp();

        let agent = AiAgent {
            id: uuid::Uuid::new_v4().to_string(),
            name: name.to_string(),
            description: None,
            user_prompt: user_prompt.to_string(),
            llm_backend_id: None,
            parsed_intent: None,
            resources: vec![],
            schedule: AgentSchedule {
                schedule_type: ScheduleType::Interval,
                interval_seconds: Some(60),
                cron_expression: None,
                timezone: None,
                event_filter: None,
            },
            status: AgentStatus::Active,
            created_at: now,
            updated_at: now,
            last_execution_at: None,
            stats: AgentStats {
                total_executions: 0,
                successful_executions: 0,
                failed_executions: 0,
                avg_duration_ms: 0,
                last_duration_ms: Some(0),
            },
            memory: AgentMemory {
                state_variables: Default::default(),
                baselines: Default::default(),
                learned_patterns: vec![],
                trend_data: vec![],
                updated_at: now,
                working: WorkingMemory::default(),
                short_term: ShortTermMemory::default(),
                long_term: LongTermMemory::default(),
            },
            error_message: None,
            priority: 128,
            conversation_history: vec![],
            user_messages: vec![],
            conversation_summary: None,
            context_window_size: 10,
            enable_tool_chaining: false,
            max_chain_depth: 3,
        };

        self.store.save_agent(&agent).await?;
        Ok(agent)
    }

    fn generate_devices(&mut self, count: usize) {
        self.devices.clear();

        let locations = vec![
            "一号车间".to_string(),
            "二号车间".to_string(),
            "仓库A".to_string(),
            "仓库B".to_string(),
            "办公楼".to_string(),
        ];

        let device_types = vec![
            ("温度传感器", vec!["temperature"]),
            ("温湿度传感器", vec!["temperature", "humidity"]),
            ("环境传感器", vec!["temperature", "humidity", "pressure"]),
            ("能耗监控", vec!["power", "voltage", "current"]),
            ("空气质量", vec!["aqi", "co2", "pm25"]),
        ];

        for i in 0..count {
            let location = &locations[i % locations.len()];
            let (device_type, metrics) = &device_types[i % device_types.len()];

            let device = SimulatedDevice::new(
                format!("device_{:04}", i),
                format!("{}-{}", location, device_type),
                location.clone(),
            )
            .with_metrics(metrics.iter().map(|s| s.to_string()).collect())
            .with_base_values(self.get_base_values(device_type));

            self.devices.push(device);
        }
    }

    fn get_base_values(&self, device_type: &str) -> Vec<f64> {
        match device_type {
            "温度传感器" => vec![25.0],
            "温湿度传感器" => vec![25.0, 50.0],
            "环境传感器" => vec![25.0, 50.0, 1013.25],
            "能耗监控" => vec![1000.0, 220.0, 4.5],
            "空气质量" => vec![50.0, 400.0, 25.0],
            _ => vec![0.0],
        }
    }

    async fn inject_metrics_batch(&self, batch_size: usize) -> anyhow::Result<usize> {
        let mut injected = 0;
        let device_count = self.devices.len().min(batch_size);

        for device in self.devices.iter().take(device_count) {
            let metrics = device.generate_metrics();

            for (metric_name, value) in metrics {
                let event = NeoMindEvent::DeviceMetric {
                    device_id: device.id.clone(),
                    metric: metric_name,
                    value: MetricValue::Float(value),
                    timestamp: chrono::Utc::now().timestamp(),
                    quality: None,
                };

                let _ = self.event_bus.publish(event).await;
                injected += 1;
            }
        }

        Ok(injected)
    }

    async fn wait_for_events(&self, millis: u64) {
        tokio::time::sleep(Duration::from_millis(millis)).await;
    }
}

// ============================================================================
// Load Tests
// ============================================================================

#[tokio::test]
async fn test_hundreds_of_devices_metrics() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 测试: 数百个设备生成大量指标 ===");

    // Generate 200 devices
    let device_count = 200;
    ctx.generate_devices(device_count);
    println!("生成 {} 个模拟设备", device_count);

    // Calculate total metrics
    let metrics_per_device = 3;
    let total_metrics = device_count * metrics_per_device;
    println!("每设备 {} 个指标，总共 {} 个指标", metrics_per_device, total_metrics);

    // Inject metrics in batches
    let batches = 10;
    let metrics_per_batch = total_metrics / batches;

    println!("分 {} 批注入指标，每批约 {} 个", batches, metrics_per_batch);

    let start = Instant::now();

    for batch in 0..batches {
        let injected = ctx.inject_metrics_batch(device_count / batches).await?;
        println!("  批次 {}/{}: 注入 {} 个指标", batch + 1, batches, injected);
        ctx.wait_for_events(10).await;
    }

    let elapsed = start.elapsed();

    println!("\n性能指标:");
    println!("  总耗时: {:?}", elapsed);
    println!("  平均每批: {:?}", elapsed / batches as u32);
    println!("  指标注入速率: {:.0} 指标/秒", total_metrics as f64 / elapsed.as_secs_f64());

    assert!(ctx.devices.len() == device_count);
    assert!(elapsed.as_secs() < 5, "Should complete within 5 seconds");

    println!("✅ 大规模指标测试通过！");
    Ok(())
}

#[tokio::test]
async fn test_agent_with_large_dataset() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 测试: Agent 处理大数据集 ===");

    // Generate 100 devices
    let device_count = 100;
    ctx.generate_devices(device_count);

    // Create a monitor agent
    let agent = ctx.create_test_agent(
        "大规模数据监控Agent",
        &format!("监控所有 {} 个设备的 {} 个指标，检测异常值", device_count, device_count * 3),
    ).await?;

    println!("创建 Agent: {}", agent.name);

    // Execute multiple times and measure performance
    let executions = 20;
    let mut times = Vec::new();

    println!("执行 {} 次，收集性能数据...", executions);

    for i in 0..executions {
        let agent = ctx.store.get_agent(&agent.id).await?.unwrap();

        let start = Instant::now();
        let record = ctx.executor.execute_agent(agent.clone()).await?;
        let elapsed = start.elapsed();

        times.push(elapsed);

        if i % 5 == 0 {
            println!("  执行 {}/{}: {:?} - 状态: {:?}", i + 1, executions, elapsed, record.status);
        }
    }

    // Calculate statistics
    let total_time: Duration = times.iter().sum();
    let avg_time = total_time / executions as u32;
    let min_time = times.iter().min().unwrap();
    let max_time = times.iter().max().unwrap();

    println!("\n性能统计:");
    println!("  平均: {:?}", avg_time);
    println!("  最小: {:?}", min_time);
    println!("  最大: {:?}", max_time);
    println!("  总计: {:?}", total_time);

    // Check conversation history
    let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
    println!("  对话历史: {} 条", agent.conversation_history.len());

    assert_eq!(agent.conversation_history.len(), executions);

    println!("✅ 大数据集 Agent 测试通过！");
    Ok(())
}

#[tokio::test]
async fn test_conversation_history_under_load() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 测试: 负载下的对话历史管理 ===");

    ctx.generate_devices(50);

    let agent = ctx.create_test_agent(
        "压力测试Agent",
        "分析所有设备数据，生成报告",
    ).await?;

    let agent_id = agent.id.clone();
    let execution_count = 50;

    println!("执行 {} 次 Agent 执行...", execution_count);

    let start = Instant::now();

    for i in 0..execution_count {
        let agent = ctx.store.get_agent(&agent_id).await?.unwrap();
        ctx.executor.execute_agent(agent.clone()).await?;

        if (i + 1) % 10 == 0 {
            let agent = ctx.store.get_agent(&agent_id).await?.unwrap();
            println!("  进度: {}/{} - 历史记录: {}", i + 1, execution_count, agent.conversation_history.len());
        }
    }

    let elapsed = start.elapsed();

    // Verify all history was saved
    let agent = ctx.store.get_agent(&agent_id).await?.unwrap();
    assert_eq!(agent.conversation_history.len(), execution_count);

    // Verify conversation history order
    for i in 1..agent.conversation_history.len() {
        assert!(agent.conversation_history[i].timestamp >= agent.conversation_history[i-1].timestamp,
            "Conversation history should be in chronological order");
    }

    println!("\n结果:");
    println!("  总执行: {}", execution_count);
    println!("  历史记录: {}", agent.conversation_history.len());
    println!("  总耗时: {:?}", elapsed);
    println!("  平均每次: {:?}", elapsed / execution_count as u32);

    // Test context window limit
    println!("\n测试上下文窗口限制...");
    let context_window_size = agent.context_window_size;
    println!("  上下文窗口大小: {}", context_window_size);

    // The agent should only use the last N turns for LLM context
    let recent_count = agent.conversation_history.len().min(context_window_size);
    println!("  应使用最近 {} 条对话记录", recent_count);

    println!("✅ 负载下对话历史测试通过！");
    Ok(())
}

#[tokio::test]
async fn test_multi_agent_concurrent_execution() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 测试: 多 Agent 并发执行 ===");

    ctx.generate_devices(100);

    // Create multiple agents of different types
    let agents = vec![
        ("温度监控组", "监控所有温度传感器，超过35度告警"),
        ("能耗监控组", "监控能耗数据，检测异常"),
        ("开关控制组", "根据温度自动控制开关"),
        ("趋势分析组", "分析所有设备的趋势"),
    ];

    let mut agent_ids = Vec::new();

    for (name, prompt) in &agents {
        let agent = ctx.create_test_agent(name, prompt).await?;
        println!("创建: {}", agent.name);
        agent_ids.push((agent.id, name.clone()));
    }

    let execution_rounds = 10;
    println!("\n并发执行 {} 轮，每轮 {} 个 Agent...", execution_rounds, agents.len());

    let start = Instant::now();
    let mut all_times: Vec<Duration> = Vec::new();

    for round in 0..execution_rounds {
        println!("\n--- 第 {} 轮 ---", round + 1);

        for (i, (agent_id, name)) in agent_ids.iter().enumerate() {
            let agent = ctx.store.get_agent(agent_id).await?.unwrap();
            let agent_start = Instant::now();

            let record = ctx.executor.execute_agent(agent.clone()).await?;

            let elapsed = agent_start.elapsed();
            all_times.push(elapsed);

            println!("  Agent{} ({}): {:?} - 状态: {:?}",
                i + 1, name, elapsed, record.status);
        }
    }

    let total_elapsed = start.elapsed();

    // Statistics
    let total_executions = agents.len() * execution_rounds;
    let avg_time: Duration = all_times.iter().sum::<Duration>() / total_executions as u32;
    let min_time = all_times.iter().min().unwrap();
    let max_time = all_times.iter().max().unwrap();

    println!("\n多 Agent 并发统计:");
    println!("  总执行次数: {}", total_executions);
    println!("  总耗时: {:?}", total_elapsed);
    println!("  平均每次: {:?}", avg_time);
    println!("  最快: {:?}", min_time);
    println!("  最慢: {:?}", max_time);
    println!("  吞吐量: {:.2} Agent执行/秒", total_executions as f64 / total_elapsed.as_secs_f64());

    // Verify all agents have correct history
    println!("\n验证对话历史:");
    for (i, (agent_id, name)) in agent_ids.iter().enumerate() {
        let agent = ctx.store.get_agent(agent_id).await?.unwrap();
        println!("  Agent{} ({}): {} 条历史记录", i + 1, name, agent.conversation_history.len());
        assert_eq!(agent.conversation_history.len(), execution_rounds);
    }

    println!("✅ 多 Agent 并发测试通过！");
    Ok(())
}

#[tokio::test]
async fn test_command_execution_simulation() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 测试: 指令执行模拟 ===");

    ctx.generate_devices(50);

    // Create an Executor agent that should make decisions
    let agent = ctx.create_test_agent(
        "自动控制Agent",
        "当温度超过30度时，打开风扇。当温度低于20度时，关闭风扇",
    ).await?;

    let agent_id = agent.id.clone();
    println!("创建: {}", agent.name);

    let execution_count = 30;
    let mut decision_counts = Vec::new();

    println!("执行 {} 次，统计决策...", execution_count);

    for i in 0..execution_count {
        // Simulate varying temperature conditions
        let _ = ctx.inject_metrics_batch(10).await?;

        let agent = ctx.store.get_agent(&agent_id).await?.unwrap();
        let record = ctx.executor.execute_agent(agent.clone()).await?;

        let decision_count = record.decision_process.decisions.len();
        decision_counts.push(decision_count);

        if (i + 1) % 10 == 0 {
            println!("  执行 {}/{}: 决策数={}, 状态={:?}",
                i + 1, execution_count, decision_count, record.status);
        }

        ctx.wait_for_events(5).await;
    }

    // Statistics
    let total_decisions: usize = decision_counts.iter().sum();
    let avg_decisions = total_decisions as f64 / decision_counts.len() as f64;
    let max_decisions = *decision_counts.iter().max().unwrap_or(&0);
    let executions_with_decisions = decision_counts.iter().filter(|&&d| d > 0).count();

    println!("\n指令执行统计:");
    println!("  总执行次数: {}", execution_count);
    println!("  总决策数: {}", total_decisions);
    println!("  平均每次决策数: {:.2}", avg_decisions);
    println!("  单次最大决策数: {}", max_decisions);
    println!("  有决策的执行: {} ({:.1}%)",
        executions_with_decisions,
        (executions_with_decisions as f64 / execution_count as f64) * 100.0);

    // Calculate decision execution rate
    let decision_rate = if total_decisions > 0 {
        (executions_with_decisions as f64 / execution_count as f64) * 100.0
    } else {
        0.0
    };

    println!("\n决策执行率: {:.1}%", decision_rate);

    let agent = ctx.store.get_agent(&agent_id).await?.unwrap();
    println!("  对话历史: {} 条", agent.conversation_history.len());

    println!("✅ 指令执行模拟测试通过！");
    Ok(())
}

#[tokio::test]
#[ignore = "Requires Ollama LLM backend"]
async fn test_real_llm_with_large_dataset() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(true).await?;

    println!("\n=== 测试: 真实LLM处理大数据集 ===");

    // Check if Ollama is available
    let addr = std::net::SocketAddr::from(([127, 0, 0, 1], 11434));
    match std::net::TcpStream::connect_timeout(&addr, Duration::from_secs(2)) {
        Ok(_) => {},
        Err(_) => {
            println!("⚠️  Ollama 未运行，跳过测试");
            return Ok(());
        }
    }

    // Generate many devices with historical data
    let device_count = 50;
    ctx.generate_devices(device_count);
    println!("生成 {} 个设备，每设备 50 个历史数据点", device_count);

    let mut total_data_points = 0;

    // Create multiple agents
    let test_cases = vec![
        ("温度监控Agent", "监控所有温度传感器，超过35度告警，低于10度告警"),
        ("综合分析Agent", "分析所有设备的综合数据趋势，识别异常模式"),
        ("自动控制Agent", "当温度超过30度时启动降温，低于15度时启动加热"),
    ];

    for (name, prompt) in test_cases {
        println!("\n--- 测试: {} ---", name);

        let agent = ctx.create_test_agent(name, prompt).await?;
        let executions = 5;
        let mut times = Vec::new();

        for i in 0..executions {
            // Inject fresh metrics
            let injected = ctx.inject_metrics_batch(20).await?;
            total_data_points += injected;

            let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
            let start = Instant::now();
            let record = ctx.executor.execute_agent(agent.clone()).await?;
            let elapsed = start.elapsed();
            times.push(elapsed);

            println!("  执行 {}/{}: {:?} - 分析长度: {} 字符",
                i + 1, executions, elapsed,
                record.decision_process.situation_analysis.len());
        }

        let avg_time = times.iter().sum::<Duration>() / executions as u32;
        println!("  平均耗时: {:?}", avg_time);

        // Verify history
        let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
        println!("  对话历史: {} 条", agent.conversation_history.len());
    }

    println!("\n总计处理数据点: {}", total_data_points);

    println!("✅ 真实LLM大数据集测试通过！");
    Ok(())
}

#[tokio::test]
async fn test_performance_benchmark() -> anyhow::Result<()> {
    let mut ctx = LoadTestContext::new_with_llm(false).await?;

    println!("\n=== 性能基准测试 ===");

    let mut metrics = TestMetrics::default();

    // Test 1: Scale test
    println!("\n[测试1] 扩展性测试");
    let scales = vec![10, 50, 100, 200];

    for scale in scales {
        ctx.generate_devices(scale);

        let agent = ctx.create_test_agent(
            &format!("性能测试Agent_{}", scale),
            &format!("监控 {} 个设备", scale),
        ).await?;

        let start = Instant::now();
        let record = ctx.executor.execute_agent(agent.clone()).await?;
        let elapsed = start.elapsed();

        println!("  {} 设备: {:?} - 状态: {:?}", scale, elapsed, record.status);
        metrics.total_devices = scale;
    }

    // Test 2: Throughput test
    println!("\n[测试2] 吞吐量测试");
    ctx.generate_devices(100);

    let agent = ctx.create_test_agent("吞吐量测试Agent", "监控所有设备").await?;

    let iterations = 50;
    let start = Instant::now();

    for _ in 0..iterations {
        let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
        ctx.executor.execute_agent(agent.clone()).await.ok();
    }

    let elapsed = start.elapsed();
    let throughput = iterations as f64 / elapsed.as_secs_f64();

    println!("  {} 次执行耗时: {:?}", iterations, elapsed);
    println!("  吞吐量: {:.2} 执行/秒", throughput);

    // Test 3: Memory efficiency
    println!("\n[测试3] 内存效率测试");

    let agent = ctx.create_test_agent("内存测试Agent", "分析数据").await?;

    // Execute many times and check conversation history doesn't grow unbounded
    for i in 0..20 {
        let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
        ctx.executor.execute_agent(agent.clone()).await.ok();

        if (i + 1) % 5 == 0 {
            let agent = ctx.store.get_agent(&agent.id).await?.unwrap();
            println!("  执行 {}: 历史记录 = {} 条", i + 1, agent.conversation_history.len());
        }
    }

    // Test 4: Concurrent agents
    println!("\n[测试4] 并发Agent测试");

    let concurrent_agents = 10;
    let executions_per_agent = 5;

    let mut agent_ids = Vec::new();
    for i in 0..concurrent_agents {
        let agent = ctx.create_test_agent(
            &format!("并发Agent_{}", i),
            "监控设备",
        ).await?;
        agent_ids.push(agent.id);
    }

    let start = Instant::now();

    for _ in 0..executions_per_agent {
        for agent_id in &agent_ids {
            let agent = ctx.store.get_agent(agent_id).await?.unwrap();
            ctx.executor.execute_agent(agent.clone()).await.ok();
        }
    }

    let elapsed = start.elapsed();
    let total_concurrent_executions = concurrent_agents * executions_per_agent;

    println!("  {} 个Agent x {} 次执行 = {} 次总执行",
        concurrent_agents, executions_per_agent, total_concurrent_executions);
    println!("  总耗时: {:?}", elapsed);
    println!("  平均每次: {:?}", elapsed / total_concurrent_executions as u32);

    metrics.total_executions = total_concurrent_executions;
    metrics.successful_executions = total_concurrent_executions;
    metrics.avg_execution_time_ms = (elapsed / total_concurrent_executions as u32).as_millis() as u64;

    metrics.print_summary();

    println!("✅ 性能基准测试通过！");
    Ok(())
}
