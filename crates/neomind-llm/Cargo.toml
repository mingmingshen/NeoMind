[package]
name = "neomind-llm"
version.workspace = true
edition.workspace = true

[dependencies]
neomind-core = { path = "../neomind-core" }
neomind-storage = { path = "../neomind-storage" }

tokio = { workspace = true }
tokio-stream = "0.1"
futures = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
async-trait = { workspace = true }

# HTTP client for API backends
reqwest = { version = "0.12", features = ["json", "stream"], optional = true }

[features]
default = ["ollama"]

# Local LLM backend (Ollama - uses llama.cpp internally)
ollama = ["reqwest"]

# Cloud backends (requires HTTP client)
cloud = ["reqwest"]
openai = ["cloud"]
anthropic = ["cloud"]
google = ["cloud"]
xai = ["cloud"]

# All backends
all = ["ollama", "cloud", "openai", "anthropic", "google", "xai"]

[dev-dependencies]
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
futures = { workspace = true }
