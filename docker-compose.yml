# NeoMind Docker Compose configuration
# Quick deployment: docker compose up -d

services:
  neomind:
    image: camthink-ai/neomind:latest
    container_name: neomind
    restart: unless-stopped

    # Ports
    ports:
      - "9375:9375"

    # Environment variables
    environment:
      - RUST_LOG=info
      - NEOMIND_DATA_DIR=/data

    # Volumes
    volumes:
      # Persistent data storage
      - neomind-data:/data
      # Optional: Mount config file
      # - ./config.toml:/app/config.toml:ro

    # Optional: Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    # Health check
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9375/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Optional: Ollama for local LLM
  # Uncomment if you want to run Ollama alongside NeoMind
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: unless-stopped
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '4'
  #         memory: 8G

volumes:
  neomind-data:
    driver: local
  # ollama-data:
  #   driver: local

# Optional: Network configuration
# networks:
#   default:
#     name: neomind-network
